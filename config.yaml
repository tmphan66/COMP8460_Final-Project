project:
  name: meditron_simple
models:
  llm:
    provider: ollama
    model: "gemma3:4b"
    temperature: 0.2
    max_tokens: 700
  embeddings:
    backend: "ollama"
    name: "nomic-embed-text"
retrieval:
  chunk_size: 800
  chunk_overlap: 160
  k: 5
  k_final: 3
privacy:
  block_on_phi_leak: false
# We add this section back, but set 'enable' to false
umls_linking:
  enable: false
  k: 1
  threshold: 0.75